{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load language_classifier.py\n",
    "#!/usr/bin/python3.6\n",
    "\n",
    "# Language classifier miniproject for machine learning module\n",
    "# LACC 2018\n",
    "import string\n",
    "from math import log\n",
    "def train(training_set):\n",
    "# train(training_set)\n",
    "#\n",
    "# Loads a language training set from a text file\n",
    "#\n",
    "# input: name of the training set (for example, \"french.txt\")\n",
    "# output: dictionary containing word/frequency pairs and total number of training words\n",
    "# \n",
    "# Note: You can open a file using \n",
    "# with open(\"filename.txt\") as f: \n",
    "#     <do stuff with f>\n",
    "#                                     \n",
    "# You can get a list containing each line with file.readlines()\n",
    "#\n",
    "# You'll need to grab each word from each line, and add 1 to the \n",
    "# frequency of that word in your dictionary. Try to strip out symbols \". ? ! , # : ;\"\n",
    "#\n",
    "# Consult https://docs.python.org/3/tutorial/inputoutput.html for reading lines.\n",
    "#\n",
    "# You can learn more about Python dictionaries online: http://www.tutorialspoint.com/python/python_dictionary.htm\n",
    "#*************************************\n",
    "# This is where you write your code\n",
    "#\n",
    "##\n",
    "    dict = {}\n",
    "    with open(training_set) as f :\n",
    "        d = f.readlines()\n",
    "    for s in d :\n",
    "        exclude = set(string.punctuation)\n",
    "        s = ''.join(ch for ch in s if ch not in exclude)\n",
    "        temp = s.split(\" \")\n",
    "        for i in range(len(temp)) :\n",
    "            word = temp[i].lower()\n",
    "            if word.endswith(\"\\n\") :\n",
    "                word = word[:-1]\n",
    "            if (word in dict) :\n",
    "                dict[word] += 1\n",
    "            else :\n",
    "                dict[word] = 1\n",
    "    #print(dict)\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "def classify(language1, N1, language2, N2, testfile):\n",
    "    #pass\n",
    "    ## \n",
    "    #\n",
    "    # Classifies the phrases in testfile as being from language1 or language2 \n",
    "    #\n",
    "    # input: the language dictionaries for language1 and language2\n",
    "    #        N1, N2 the number of words in the training set for language1 and language 2 respectively\n",
    "    #        and the testfile containing text to be classified\n",
    "    # output: 0/1 for which of the two languages \n",
    "    # \n",
    "    # You should use a naive Bayes classifier. Break up the phrase \n",
    "    # to be classified into separate words, and compute the probability\n",
    "    # of each word to be from the French language (with the help of the \n",
    "    # dictionaries). Use the formula:\n",
    "    # P(word|French) = (# of copies of word in French training set + 1) \n",
    "    #\t\t\t\t\t/ (# of words in training set + 1)\n",
    "    # The overall probability of the phrase is the product of all the \n",
    "    # word probabilities (because of the naive independence assumption)\n",
    "    #\n",
    "    # Compute a probability for French and one for Spanish\n",
    "    # The larger is the one we classify to\n",
    "\n",
    "    #*************************************\n",
    "    # Write your code here\n",
    "    t = open(testfile, 'r').readlines()\n",
    "    prob_lang1 = 0\n",
    "    prob_lang2 = 0\n",
    "    li =[]\n",
    "    for a in t :\n",
    "        s = a.split(\" \")\n",
    "        for i in range(len(s)) :\n",
    "            w = s[i].lower()\n",
    "            exclude = set(string.punctuation)\n",
    "            w = ''.join(ch for ch in w if ch not in exclude)\n",
    "            li.append(w)\n",
    "    #print(li)\n",
    "    sc = 0\n",
    "    fc = 0\n",
    "    for word in li :\n",
    "        if word in language1 :\n",
    "            prob_lang1 += log(language1[word] / N1)\n",
    "            #print(\"F\")\n",
    "            fc += 1\n",
    "        if word in language2 :\n",
    "            prob_lang2 += log(language2[word] / N2)\n",
    "            #print(\"S\")\n",
    "            sc += 1\n",
    "    #if(prob_lang1 > prob_lang2) :\n",
    "    #    return \"French\"\n",
    "    #else :\n",
    "     #   return \"Spanish\"\n",
    "    return int(prob_lang1 > prob_lang2)\n",
    "    #*************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call train on the french and spanish training files and classify on the test file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "frenchTrain = train(\"french.txt\")\n",
    "spanishTrain = train(\"spanish.txt\")\n",
    "x = classify(frenchTrain, len(frenchTrain), spanishTrain, len(spanishTrain), \"spanish.txt\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand your training dataset of french and spanish significantly from the Internet. Rerun with new training datasets. See if your model works well with your neighbors training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
